{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "071a3855-d4e9-4272-807f-8c19b1e05ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9254bca0-fd0e-4e00-acce-5caccd641f88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_url = \"https://apps.compu-flair.com\"\n",
    "apps = ['TCGA', 'scRNAseq', 'scRNAseq2', 'scRNAseqDEG','scRNAseqFilterRawCounts', 'geneSetAnalys', 'scRNAseqCellType']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d7a8000-4a7d-464d-9299-c710b5924abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://apps.compu-flair.com/apps/TCGA/description#section-what-is-this\n",
      "TCGA.txt\n",
      "Text written to all_apps/TCGA.txt\n",
      "https://apps.compu-flair.com/apps/scRNAseq/description#section-what-is-this\n",
      "scRNAseq.txt\n",
      "Text written to all_apps/scRNAseq.txt\n",
      "https://apps.compu-flair.com/apps/scRNAseq2/description#section-what-is-this\n",
      "scRNAseq2.txt\n",
      "Text written to all_apps/scRNAseq2.txt\n",
      "https://apps.compu-flair.com/apps/scRNAseqDEG/description#section-what-is-this\n",
      "scRNAseqDEG.txt\n",
      "Text written to all_apps/scRNAseqDEG.txt\n",
      "https://apps.compu-flair.com/apps/scRNAseqFilterRawCounts/description#section-what-is-this\n",
      "scRNAseqFilterRawCounts.txt\n",
      "Text written to all_apps/scRNAseqFilterRawCounts.txt\n",
      "https://apps.compu-flair.com/apps/geneSetAnalys/description#section-what-is-this\n",
      "geneSetAnalys.txt\n",
      "Text written to all_apps/geneSetAnalys.txt\n",
      "https://apps.compu-flair.com/apps/scRNAseqCellType/description#section-what-is-this\n",
      "scRNAseqCellType.txt\n",
      "Text written to all_apps/scRNAseqCellType.txt\n",
      "All Apps Scraped Successfully\n"
     ]
    }
   ],
   "source": [
    "for app in apps:\n",
    "    try:\n",
    "        content = []\n",
    "        app_url = f\"{base_url}/apps/{app}/description#section-what-is-this\"\n",
    "        print(app_url)\n",
    "        app_response = requests.get(app_url)\n",
    "        app_soup = BeautifulSoup(app_response.content, 'html.parser')\n",
    "        \n",
    "        # Extract and print text from the description page\n",
    "        texts = app_soup.get_text(separator='\\n', strip=True)\n",
    "        app_details = f'App name: {app}'\n",
    "        content.append(app_details)\n",
    "        content.append(texts)\n",
    "        content_string = \" \".join(content)\n",
    "\n",
    "    \n",
    "        filename = app + '.txt'\n",
    "        print(filename)\n",
    "        filepath = os.path.join('all_apps', filename)\n",
    "\n",
    "        # Writing the texts to a file\n",
    "        with open(filepath, 'w', encoding='utf-8') as file:\n",
    "            file.write(content_string)\n",
    "        print(f\"Text written to {filepath}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'An error has occurred: {e}')\n",
    "        \n",
    "print(\"All Apps Scraped Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d87b92ba-0d57-4cb5-b95d-0e799dbfe920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49524ea3-aea9-4c4e-a496-9c5860047a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load from a directory\n",
    "loader = DirectoryLoader('./all_apps/', glob=\"./*.txt\", loader_cls=TextLoader) #- We will use this in case of many articles saved in a directory\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2268cc0a-d2a7-46f7-aef8-e8a76c0068e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting the text into smaller documents \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d423561",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value:\n",
      "This column represents the probability of observing the given level of overlap between the input set and the gene set by random chance alone.\n",
      "Adjusted P-value:\n",
      "The \"Adjusted P-value\" column indicates the P-value that has been adjusted to control for multiple hypothesis testing. It accounts for the potential inflation of false positives.\n",
      "Odds Ratio:\n",
      "This column provides the ratio of the odds of finding the overlapping genes in the gene set compared to the odds of finding the overlapping genes outside the gene set.\n",
      "Combined Score:\n",
      "The \"Combined Score\" column represents the combined score for the gene set, calculated based on various statistical measures.\n",
      "Genes:\n",
      "This column lists the individual genes from the input set that were found to overlap with the gene set being analyzed.\n",
      "barplot_(Database Name Here).png\n",
      ": \n",
      "    The output file barplot_(Database Name Here).png is a visual representation of the Gene Set \n",
      "    Enrichment Analysis (GSEA) results related to the database.\n"
     ]
    }
   ],
   "source": [
    "print(texts[2].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4068381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#chunks: 91 #pages: 7\n"
     ]
    }
   ],
   "source": [
    "print(f\"#chunks: {len(texts)} #pages: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4e5cb2a-30aa-41bc-a7ca-bc35a3edc104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acelogic/Jupyter Environs/langchain/venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. Use langchain_openai.OpenAIEmbeddings instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('openai_api_key')\n",
    "\n",
    "# Embed and store the texts\n",
    "embedding_function = OpenAIEmbeddings(model = 'text-embedding-ada-002',openai_api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e8adf9d-614f-4b69-b083-f3363c153528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pinecone\n",
    "# from langchain.vectorstores import Pinecone\n",
    "# from pinecone.core.client.configuration import Configuration as OpenApiConfiguration\n",
    "\n",
    "# pinecone_api_key = os.getenv(\"pinecone_api_key\")\n",
    "# pinecone_environ = os.getenv(\"pinecone_environ\")\n",
    "# def pinecone_setup():\n",
    "#     try:\n",
    "#         # Initialize Pinecone from the database\n",
    "#         openapi_config = OpenApiConfiguration.get_default_copy()\n",
    "#         openapi_config.proxy = \"http://proxy.server:3128\"\n",
    "#         pinecone.init(api_key=pinecone_api_key, environment=pinecone_environ)\n",
    "#         print(\"success\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to initialize Pinecone: {e}\")\n",
    "# pinecone_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbebef30-9c24-4744-a413-4215479908b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "'''\n",
    "index_name = 'compflair'  # Already created at Pinecone console\n",
    "\n",
    "indexes_list = pinecone.list_indexes()\n",
    "print(indexes_list)\n",
    "\n",
    "def load_docs_to_vectorstore():\n",
    "    if index_name in indexes_list:\n",
    "        try:\n",
    "            pinecone_setup()\n",
    "            \n",
    "            docsearch = Pinecone.from_documents(texts,embedding=embedding_function,index_name=index_name)\n",
    "            return docsearch\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred  {e} \")\n",
    " \n",
    "docsearch = load_docs_to_vectorstore()\n",
    "'''\n",
    "\n",
    "# load it into Chroma\n",
    "db = Chroma.from_documents(texts, embedding_function)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed376570-9bdd-40e3-bbdb-8c8613864c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever(query):\n",
    "    retriever = db.as_retriever(search_kwargs={\"k\": 10})\n",
    "    docs = retriever.get_relevant_documents(query) # Here we are filtering documents with similar meaning to the query\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "184d6772-5536-453c-b7d1-aef1f37a01ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your OpenAI API key here\n",
    "OPENAI_API_KEY = os.getenv('openai_api_key')\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "def summarize_query(query, documents):\n",
    "    # Construct the conversation with a more explicit JSON formatting instruction\n",
    "    messages = [{\"role\": \"system\",\n",
    "                 \"content\": \"\"\"\n",
    "                 You are a helpful research assistant. \n",
    "                 You will be given a series of documents and a question. Answer the question based on the given documents.\n",
    "\n",
    "                 Your output format should be a json file.  \n",
    "                 \"\"\"\n",
    "                }]\n",
    "\n",
    "    # Append documents and query\n",
    "    for doc in documents:\n",
    "        content = doc.page_content if hasattr(doc, 'page_content') else ''\n",
    "        messages.append({\"role\": \"user\", \"content\": content})\n",
    "    messages.append({\"role\": \"user\", \"content\": query})\n",
    "\n",
    "    # Make the API call\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=messages,\n",
    "            temperature=0.7  # Adjust creativity\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4ca2b09-cc76-45f9-884e-d57a52a74deb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"application_recommendation\": \"You should use the 10X pre-scRNAseq application for processing your fastq.gz files. This application is designed specifically for single-cell RNA sequencing (scRNA-seq) data and will provide outputs such as multiqc_report.html and genes.tsv, which are essential for downstream analysis.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "what are possible analyses in this website?\n",
    "\"\"\" \n",
    "query = \"\"\"\n",
    "I have a bunch of fastq.gz files. What application shall I use?\n",
    "\"\"\" \n",
    "# docs = retriever(query)\n",
    "docs = db.similarity_search(query)\n",
    "summary = summarize_query(query, documents=docs)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7091e9e9-d6e4-4cab-9622-0fd2305423ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"application_recommendation\": \"You can use the PreProcessing 10X scRNAseq application for processing your fastq.gz files for single-cell RNA sequencing (scRNAseq) analysis. This application is designed to handle 10X Genomics data and can preprocess the raw fastq files to generate the required genes.tsv, barcodes.tsv, and matrix.mtx files for downstream analysis.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "I have a bunch of fastq.gz files. What application shall I use?\n",
    "\"\"\" \n",
    "docs = retriever(query)\n",
    "summary = summarize_query(query, documents=docs)\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
